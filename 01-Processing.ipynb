{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "In this notebook, I will be loading the data necessary for this project, combining the data sources and performing initial data processing steps. I will also be performing some exploratory data analysis for the purposes of identifying missing values and outliers, which will then be followed up with the appropriate processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.util.paths import DATA_PATH\n",
    "from lib.processing import load_from_pkl\n",
    "from lib.pipelines import extracted_pipe, api_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this project has been sourced from Discogs.com, the largest online marketplace for second-hand physical music. There are three components to the data that will make up our final dataset, namely:\n",
    "1. api_data -> Data taken from the official Discogs.com API (https://www.discogs.com/developers)\n",
    "2. extracted_data -> Data scraped from Discogs release pages\n",
    "3. image_embedding_data -> High-Level Features extracted from the cover images of each Album\n",
    "\n",
    "At this juncture, we will load, investigate and transform the first two data sources outlined above. The data was collected continuously over the months of February and March 2020 using the scripts found in the data directory of this project. To scrape each of these three data sources, the main() function of the data/main.py file was used. It is not recommended to run this script oneself, as it will require investing into a paid proxy service due to the rate limiting in force by Discogs.com. The data has been made available for the EPFL Extension School Reviewers at INSERT_DATA_SOURCE_HERE. For more details on how each data source was filtered and scraped, please refer to the classes and functions contained in the data/util/scrape.py module.\n",
    "    \n",
    "First, we will load the data extracted from the Discogs.com API, henceforth referred to as ``api_data``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Data\n",
    "### Loading and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data = load_from_pkl('api',path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>release_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>genre</th>\n",
       "      <th>style</th>\n",
       "      <th>label</th>\n",
       "      <th>community_have</th>\n",
       "      <th>community_want</th>\n",
       "      <th>formats</th>\n",
       "      <th>master_id</th>\n",
       "      <th>thumb_url</th>\n",
       "      <th>release_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11918321</td>\n",
       "      <td>Bing Crosby - Crosbyana</td>\n",
       "      <td>1934</td>\n",
       "      <td>Canada</td>\n",
       "      <td>b'\\x80\\x03]q\\x00(X\\x04\\x00\\x00\\x00Jazzq\\x01X\\x...</td>\n",
       "      <td>b'\\x80\\x03]q\\x00(X\\x08\\x00\\x00\\x00Big Bandq\\x0...</td>\n",
       "      <td>b'\\x80\\x03]q\\x00(X\\x05\\x00\\x00\\x00Deccaq\\x01X\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>b'\\x80\\x03]q\\x00}q\\x01(X\\x03\\x00\\x00\\x00qtyq\\x...</td>\n",
       "      <td>1354381</td>\n",
       "      <td>https://img.discogs.com/J7vwmOhWMdUJ5vYuaYZvIj...</td>\n",
       "      <td>https://api.discogs.com/releases/11918321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10550056</td>\n",
       "      <td>Bing Crosby - Crosbyana</td>\n",
       "      <td>1934</td>\n",
       "      <td>US</td>\n",
       "      <td>b'\\x80\\x03]q\\x00(X\\x04\\x00\\x00\\x00Jazzq\\x01X\\x...</td>\n",
       "      <td>b'\\x80\\x03]q\\x00(X\\x08\\x00\\x00\\x00Big Bandq\\x0...</td>\n",
       "      <td>b'\\x80\\x03]q\\x00X\\x05\\x00\\x00\\x00Deccaq\\x01a.'</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>b'\\x80\\x03]q\\x00}q\\x01(X\\x03\\x00\\x00\\x00qtyq\\x...</td>\n",
       "      <td>1354381</td>\n",
       "      <td>https://img.discogs.com/aLpqYUso3yY53XDHwiqqB-...</td>\n",
       "      <td>https://api.discogs.com/releases/10550056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6910984</td>\n",
       "      <td>Tommy Dorsey And His Clambake Seven - Tommy Do...</td>\n",
       "      <td>1935</td>\n",
       "      <td>US</td>\n",
       "      <td>b'\\x80\\x03]q\\x00X\\x04\\x00\\x00\\x00Jazzq\\x01a.'</td>\n",
       "      <td>b'\\x80\\x03]q\\x00X\\x05\\x00\\x00\\x00Swingq\\x01a.'</td>\n",
       "      <td>b'\\x80\\x03]q\\x00(X\\r\\x00\\x00\\x00Swing Classicq...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>b'\\x80\\x03]q\\x00}q\\x01(X\\x0c\\x00\\x00\\x00descri...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://img.discogs.com/FkuaZ7cqdBt5-TvS2ck0hP...</td>\n",
       "      <td>https://api.discogs.com/releases/6910984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>12959431</td>\n",
       "      <td>Paul Whiteman And His Orchestra, Bix Beiderbec...</td>\n",
       "      <td>1936</td>\n",
       "      <td>US</td>\n",
       "      <td>b'\\x80\\x03]q\\x00X\\x04\\x00\\x00\\x00Jazzq\\x01a.'</td>\n",
       "      <td>b'\\x80\\x03]q\\x00X\\x05\\x00\\x00\\x00Swingq\\x01a.'</td>\n",
       "      <td>b'\\x80\\x03]q\\x00X\\x06\\x00\\x00\\x00Victorq\\x01a.'</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>b'\\x80\\x03]q\\x00}q\\x01(X\\x0c\\x00\\x00\\x00descri...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://img.discogs.com/Wg31rg_x6TtOMz-jIDC-3l...</td>\n",
       "      <td>https://api.discogs.com/releases/12959431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4453491</td>\n",
       "      <td>Jimmie Lunceford And His Orchestra - For Dance...</td>\n",
       "      <td>1937</td>\n",
       "      <td>Canada</td>\n",
       "      <td>b'\\x80\\x03]q\\x00X\\x04\\x00\\x00\\x00Jazzq\\x01a.'</td>\n",
       "      <td>b'\\x80\\x03]q\\x00.'</td>\n",
       "      <td>b'\\x80\\x03]q\\x00(X\\x05\\x00\\x00\\x00Deccaq\\x01X\\...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>b'\\x80\\x03]q\\x00}q\\x01(X\\x0c\\x00\\x00\\x00descri...</td>\n",
       "      <td>1519538</td>\n",
       "      <td></td>\n",
       "      <td>https://api.discogs.com/releases/4453491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  release_id                                              title  year  \\\n",
       "0   1    11918321                            Bing Crosby - Crosbyana  1934   \n",
       "1   2    10550056                            Bing Crosby - Crosbyana  1934   \n",
       "2   3     6910984  Tommy Dorsey And His Clambake Seven - Tommy Do...  1935   \n",
       "3   4    12959431  Paul Whiteman And His Orchestra, Bix Beiderbec...  1936   \n",
       "4   5     4453491  Jimmie Lunceford And His Orchestra - For Dance...  1937   \n",
       "\n",
       "  country                                              genre  \\\n",
       "0  Canada  b'\\x80\\x03]q\\x00(X\\x04\\x00\\x00\\x00Jazzq\\x01X\\x...   \n",
       "1      US  b'\\x80\\x03]q\\x00(X\\x04\\x00\\x00\\x00Jazzq\\x01X\\x...   \n",
       "2      US      b'\\x80\\x03]q\\x00X\\x04\\x00\\x00\\x00Jazzq\\x01a.'   \n",
       "3      US      b'\\x80\\x03]q\\x00X\\x04\\x00\\x00\\x00Jazzq\\x01a.'   \n",
       "4  Canada      b'\\x80\\x03]q\\x00X\\x04\\x00\\x00\\x00Jazzq\\x01a.'   \n",
       "\n",
       "                                               style  \\\n",
       "0  b'\\x80\\x03]q\\x00(X\\x08\\x00\\x00\\x00Big Bandq\\x0...   \n",
       "1  b'\\x80\\x03]q\\x00(X\\x08\\x00\\x00\\x00Big Bandq\\x0...   \n",
       "2     b'\\x80\\x03]q\\x00X\\x05\\x00\\x00\\x00Swingq\\x01a.'   \n",
       "3     b'\\x80\\x03]q\\x00X\\x05\\x00\\x00\\x00Swingq\\x01a.'   \n",
       "4                                 b'\\x80\\x03]q\\x00.'   \n",
       "\n",
       "                                               label  community_have  \\\n",
       "0  b'\\x80\\x03]q\\x00(X\\x05\\x00\\x00\\x00Deccaq\\x01X\\...               1   \n",
       "1     b'\\x80\\x03]q\\x00X\\x05\\x00\\x00\\x00Deccaq\\x01a.'               4   \n",
       "2  b'\\x80\\x03]q\\x00(X\\r\\x00\\x00\\x00Swing Classicq...               4   \n",
       "3    b'\\x80\\x03]q\\x00X\\x06\\x00\\x00\\x00Victorq\\x01a.'               3   \n",
       "4  b'\\x80\\x03]q\\x00(X\\x05\\x00\\x00\\x00Deccaq\\x01X\\...               5   \n",
       "\n",
       "   community_want                                            formats  \\\n",
       "0               2  b'\\x80\\x03]q\\x00}q\\x01(X\\x03\\x00\\x00\\x00qtyq\\x...   \n",
       "1               4  b'\\x80\\x03]q\\x00}q\\x01(X\\x03\\x00\\x00\\x00qtyq\\x...   \n",
       "2               2  b'\\x80\\x03]q\\x00}q\\x01(X\\x0c\\x00\\x00\\x00descri...   \n",
       "3               3  b'\\x80\\x03]q\\x00}q\\x01(X\\x0c\\x00\\x00\\x00descri...   \n",
       "4               2  b'\\x80\\x03]q\\x00}q\\x01(X\\x0c\\x00\\x00\\x00descri...   \n",
       "\n",
       "   master_id                                          thumb_url  \\\n",
       "0    1354381  https://img.discogs.com/J7vwmOhWMdUJ5vYuaYZvIj...   \n",
       "1    1354381  https://img.discogs.com/aLpqYUso3yY53XDHwiqqB-...   \n",
       "2          0  https://img.discogs.com/FkuaZ7cqdBt5-TvS2ck0hP...   \n",
       "3          0  https://img.discogs.com/Wg31rg_x6TtOMz-jIDC-3l...   \n",
       "4    1519538                                                      \n",
       "\n",
       "                                 release_url  \n",
       "0  https://api.discogs.com/releases/11918321  \n",
       "1  https://api.discogs.com/releases/10550056  \n",
       "2   https://api.discogs.com/releases/6910984  \n",
       "3  https://api.discogs.com/releases/12959431  \n",
       "4   https://api.discogs.com/releases/4453491  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see the data saved from the querying of the Discogs.com API. The data includes all available jazz albums from the API and retains the columns that were deemed to be the most relevant and informative for the purposes of estimating the market value of each record. As we can see from the above calling of the ``.head()`` method on the api_data DataFrame, several columns have been saved in a binary format. This is due to the fact that the API often returned multiple categories for these columns, and as such they were initially saved in a list in the process of scraping. As this data comes from a SQL database, it has been pickled to enable the storage of the data. Let us now unpickle this data in order to get a better understanding of the structure of the ``api_data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>release_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>genre</th>\n",
       "      <th>style</th>\n",
       "      <th>label</th>\n",
       "      <th>community_have</th>\n",
       "      <th>community_want</th>\n",
       "      <th>formats</th>\n",
       "      <th>master_id</th>\n",
       "      <th>thumb_url</th>\n",
       "      <th>release_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11918321</td>\n",
       "      <td>Bing Crosby - Crosbyana</td>\n",
       "      <td>1934</td>\n",
       "      <td>Canada</td>\n",
       "      <td>[Jazz, Pop]</td>\n",
       "      <td>[Big Band, Vocal]</td>\n",
       "      <td>[Decca, The Compo Company Ltd.]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'qty': '6', 'descriptions': ['10\"', '78 RPM'...</td>\n",
       "      <td>1354381</td>\n",
       "      <td>https://img.discogs.com/J7vwmOhWMdUJ5vYuaYZvIj...</td>\n",
       "      <td>https://api.discogs.com/releases/11918321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10550056</td>\n",
       "      <td>Bing Crosby - Crosbyana</td>\n",
       "      <td>1934</td>\n",
       "      <td>US</td>\n",
       "      <td>[Jazz, Pop]</td>\n",
       "      <td>[Big Band, Vocal]</td>\n",
       "      <td>[Decca]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[{'qty': '6', 'descriptions': ['10\"', '78 RPM'...</td>\n",
       "      <td>1354381</td>\n",
       "      <td>https://img.discogs.com/aLpqYUso3yY53XDHwiqqB-...</td>\n",
       "      <td>https://api.discogs.com/releases/10550056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6910984</td>\n",
       "      <td>Tommy Dorsey And His Clambake Seven - Tommy Do...</td>\n",
       "      <td>1935</td>\n",
       "      <td>US</td>\n",
       "      <td>[Jazz]</td>\n",
       "      <td>[Swing]</td>\n",
       "      <td>[Swing Classic, RCA Victor]</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'descriptions': ['10\"', '78 RPM', 'Album', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://img.discogs.com/FkuaZ7cqdBt5-TvS2ck0hP...</td>\n",
       "      <td>https://api.discogs.com/releases/6910984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>12959431</td>\n",
       "      <td>Paul Whiteman And His Orchestra, Bix Beiderbec...</td>\n",
       "      <td>1936</td>\n",
       "      <td>US</td>\n",
       "      <td>[Jazz]</td>\n",
       "      <td>[Swing]</td>\n",
       "      <td>[Victor]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[{'descriptions': ['10\"', '78 RPM', 'Album', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://img.discogs.com/Wg31rg_x6TtOMz-jIDC-3l...</td>\n",
       "      <td>https://api.discogs.com/releases/12959431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4453491</td>\n",
       "      <td>Jimmie Lunceford And His Orchestra - For Dance...</td>\n",
       "      <td>1937</td>\n",
       "      <td>Canada</td>\n",
       "      <td>[Jazz]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Decca, Decca Records, Inc.]</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'descriptions': ['10\"', '78 RPM', 'Album'], ...</td>\n",
       "      <td>1519538</td>\n",
       "      <td></td>\n",
       "      <td>https://api.discogs.com/releases/4453491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  release_id                                              title  year  \\\n",
       "0   1    11918321                            Bing Crosby - Crosbyana  1934   \n",
       "1   2    10550056                            Bing Crosby - Crosbyana  1934   \n",
       "2   3     6910984  Tommy Dorsey And His Clambake Seven - Tommy Do...  1935   \n",
       "3   4    12959431  Paul Whiteman And His Orchestra, Bix Beiderbec...  1936   \n",
       "4   5     4453491  Jimmie Lunceford And His Orchestra - For Dance...  1937   \n",
       "\n",
       "  country        genre              style                            label  \\\n",
       "0  Canada  [Jazz, Pop]  [Big Band, Vocal]  [Decca, The Compo Company Ltd.]   \n",
       "1      US  [Jazz, Pop]  [Big Band, Vocal]                          [Decca]   \n",
       "2      US       [Jazz]            [Swing]      [Swing Classic, RCA Victor]   \n",
       "3      US       [Jazz]            [Swing]                         [Victor]   \n",
       "4  Canada       [Jazz]                 []     [Decca, Decca Records, Inc.]   \n",
       "\n",
       "   community_have  community_want  \\\n",
       "0               1               2   \n",
       "1               4               4   \n",
       "2               4               2   \n",
       "3               3               3   \n",
       "4               5               2   \n",
       "\n",
       "                                             formats  master_id  \\\n",
       "0  [{'qty': '6', 'descriptions': ['10\"', '78 RPM'...    1354381   \n",
       "1  [{'qty': '6', 'descriptions': ['10\"', '78 RPM'...    1354381   \n",
       "2  [{'descriptions': ['10\"', '78 RPM', 'Album', '...          0   \n",
       "3  [{'descriptions': ['10\"', '78 RPM', 'Album', '...          0   \n",
       "4  [{'descriptions': ['10\"', '78 RPM', 'Album'], ...    1519538   \n",
       "\n",
       "                                           thumb_url  \\\n",
       "0  https://img.discogs.com/J7vwmOhWMdUJ5vYuaYZvIj...   \n",
       "1  https://img.discogs.com/aLpqYUso3yY53XDHwiqqB-...   \n",
       "2  https://img.discogs.com/FkuaZ7cqdBt5-TvS2ck0hP...   \n",
       "3  https://img.discogs.com/Wg31rg_x6TtOMz-jIDC-3l...   \n",
       "4                                                      \n",
       "\n",
       "                                 release_url  \n",
       "0  https://api.discogs.com/releases/11918321  \n",
       "1  https://api.discogs.com/releases/10550056  \n",
       "2   https://api.discogs.com/releases/6910984  \n",
       "3  https://api.discogs.com/releases/12959431  \n",
       "4   https://api.discogs.com/releases/4453491  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_data.applymap(lambda x: pickle.loads(x) if isinstance(x,bytes) else x).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all columns are now human-readable, we can discuss each column and its relevance for the purposes of our goal of estimating the market value of jazz albums on the basis of their meta-characteristics\n",
    "- ``release_id`` and ``master_id``\n",
    "    - These columns represent the unique identifier of a specific release of a record on Discogs.com, and the unique identifier of the album irrespective of the release, respectively.\n",
    "    - While ``release_id`` will be of no use to us in the estimation of album market value, it is valuable as a primary key for the joining of the data extracted from the Discogs.com API with the scraped release page and image data we will be introducing later\n",
    "    - ``master_id`` will be useful in constructing linkages between entries that are the same album, but released in a different country, format, or by another label\n",
    "- ``country``\n",
    "    - This feature gives us an insight into which country the record was released from\n",
    "    - While not immediately obvious from the snapshot above, this feature can have multiple countries for its value, such as \"England & USA\", which requires a more thoughtful approach than just direct one-hot encoding in order to optimally preserve the information it encodes\n",
    "- ``title``\n",
    "    - This feature includes both the title of the album, as well as the title of the artist\n",
    "    - It will be necessary to split this feature into two independent ones, such that entries can be linked to others by virtue of having the same authoring artist or group\n",
    "- ``community_want`` and ``community_have``\n",
    "    - These features outline the registered demand and supply, respectively for given albums on the Discogs.com platform\n",
    "    - Users can register their ownership or desire of a certain album, which is then aggregated over users and recorded in these features\n",
    "    - These are the first features we see which will not be taken into account in the record store estimation scenario, as in a physical visit to the record store, it is not possible to know exactly how many people have and want a specific record\n",
    "- ``genre``, ``style`` and ``label``\n",
    "    - These features outline the genres, styles and labels associated with each album release\n",
    "    - As has been alluded to previously, there are potentially multiple values for this feature, which will make standard encoding methods such as One-Hot Encoding difficult to rationalize\n",
    "- ``formats``\n",
    "    - Taken directly from the Discogs.com API, the formats feature is the most unruly of all, as it contains up to 4 sub-features,namely:\n",
    "        - Format Description\n",
    "            - Album release specifics\n",
    "            - Examples\n",
    "                - '10\"', '78RPM', 'Album', 'Reissue'\n",
    "        - Format Text\n",
    "            - Additional free form notes associated with the record release\n",
    "            - Examples\n",
    "                - 'Paper Sleeve', 'Red Vinyl'\n",
    "        - Format Name\n",
    "            - The name of the format\n",
    "            - Examples\n",
    "                - 'CD', 'Vinyl', 'Cassette'\n",
    "        - Format Quantity\n",
    "            - An integer representing how many units of the format are associated with a purchase of the release\n",
    "- ``thumb_url`` and ``release_url``\n",
    "    - These features are unnecessary for the purposes of our analysis here, but were useful in order to conduct the data extraction of the ``extracted_data`` and ``image_embedding_data`` obtained from the Discogs.com platform itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigation and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having taken an initial look at ``api_data``, we can now move on to the cleaning and transformation of this DataFrame through a previously written pipeline, to be found in the lib/pipelines.py module. For the purposes of exposition, the pipeline will be replicated here step-by-step, with motivation behind each step. In the following notebooks, a direct import of the pipeline will be used in lieu of a replication as below.\n",
    "\n",
    "Below the required transformers will be imported and composed into the pre-defined pipeline structure, after which the pipeline will be explained in its entirety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from lib.transformers import (ColumnRemover, \n",
    "                              TitleSplitter, \n",
    "                              Unpickler, \n",
    "                              LabelCleanReduce, \n",
    "                              ArtistCleanReduce, \n",
    "                              DuplicateRemover, \n",
    "                              CountryEncoder, \n",
    "                              GenreEncoder, \n",
    "                              MultiValueCategoricalEncoder, \n",
    "                              FormatEncoder, \n",
    "                              FormatTextCleanReduce, \n",
    "                              TimePeriodEncoder,\n",
    "                              OutlierRemover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_pipe = Pipeline([\n",
    "    #Step 4a - Homogenize and clean the label feature\n",
    "    ('label',LabelCleanReduce()),\n",
    "    #Step 4b - Homogenize and clean the artist feature\n",
    "    ('artist',ArtistCleanReduce())\n",
    "])\n",
    "\n",
    "column_encoding_pipe = Pipeline([\n",
    "    #Step 6a - Identify regions and superregions associated with countries and approrpiately encode\n",
    "    #multi-country album releases\n",
    "    ('country',CountryEncoder()),\n",
    "    #Step 6b - Expand and encode the genre feature\n",
    "    ('genre',GenreEncoder()),\n",
    "    #Step 6c - Expand and encode the style feature\n",
    "    ('style',MultiValueCategoricalEncoder(feature='style'))\n",
    "])\n",
    "\n",
    "format_pipe = Pipeline([\n",
    "    #Step 7a - Create the format_description, format_text, format_name and format_quantity features\n",
    "    ('make_columns',FormatEncoder()),\n",
    "    #Step 7b - Remove format_quantity outliers\n",
    "    ('remove_quantity_outliers', OutlierRemover('format_quantity')),\n",
    "    #Step 7c - Expand and encode the format_description feature\n",
    "    ('encode_descriptions',MultiValueCategoricalEncoder('format_description')),\n",
    "    #Step 7d - Homogenize and clean the format_text feature\n",
    "    ('clean_format_text',FormatTextCleanReduce())\n",
    "])\n",
    "\n",
    "api_pipe = Pipeline([\n",
    "    #Step 1 - Remove Unnecessary Columns\n",
    "    ('remove_columns',ColumnRemover(['id','thumb_url','release_url'])),\n",
    "    #Step 2 - Splitting title Feature into title and artist\n",
    "    ('split_title',TitleSplitter()),\n",
    "    #Step 3 - Unpickle Pickled Features\n",
    "    ('unpickle',Unpickler(['genre','style','label','formats'])),\n",
    "    #Step 4 - Clean Features with Multiple Categorical Values per Sample and High Categorical Variance\n",
    "    ('clean_text',clean_text_pipe),\n",
    "    #Step 5 - Remove Entries with Duplicate release_ids\n",
    "    ('remove_duplicates',DuplicateRemover('release_id')),\n",
    "    #Step 6 - Encode Categorical Features which cannot be encoded conventionally\n",
    "    ('encode_columns',column_encoding_pipe),\n",
    "    #Step 7 - Expand the 'format' Feature from Dictionary to Column Format\n",
    "    ('format_columns',format_pipe),\n",
    "    #Step 8 - Encode Jazz Periods and Eras associated with the Release Year of each Album\n",
    "    ('encode_time_periods',TimePeriodEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Step Exposition\n",
    "#### Step 1 - Removing Unnecessary Columns\n",
    "This step is mostly self-explanatory. For the purposes of this analysis, neither ``thumb_url`` and ``release_url`` will be relevant, and the ``id`` column is superfluous\n",
    "#### Step 2 - Splitting ``title`` Feature into ``title`` and ``artist``\n",
    "As was alluded to in the initial ``api_data`` overview, the original ``title`` feature clearly contains two distinct pieces of information, namely the name of the performing artist or group for a given release, as well as the name of said release. As such, with this transformer, we split the title feature according to the common delimiter in this column, namely a hyphen ('-') in order to yield an individual ``title`` and ``artist`` column. An equivalent operation is shown below on a sample of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bing Crosby</td>\n",
       "      <td>Crosbyana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bing Crosby</td>\n",
       "      <td>Crosbyana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tommy Dorsey And His Clambake Seven</td>\n",
       "      <td>Tommy Dorsey And His Clambake Seven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paul Whiteman And His Orchestra, Bix Beiderbec...</td>\n",
       "      <td>Dedicated To The Memory Of Bix Beiderbecke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jimmie Lunceford And His Orchestra</td>\n",
       "      <td>For Dancers Only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              artist  \\\n",
       "0                                       Bing Crosby    \n",
       "1                                       Bing Crosby    \n",
       "2               Tommy Dorsey And His Clambake Seven    \n",
       "3  Paul Whiteman And His Orchestra, Bix Beiderbec...   \n",
       "4                Jimmie Lunceford And His Orchestra    \n",
       "\n",
       "                                          title  \n",
       "0                                     Crosbyana  \n",
       "1                                     Crosbyana  \n",
       "2           Tommy Dorsey And His Clambake Seven  \n",
       "3   Dedicated To The Memory Of Bix Beiderbecke   \n",
       "4                              For Dancers Only  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_data['title'].head().str.split('-',n=1,expand=True).rename(columns={0:'artist',1:'title'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Unpickle Pickled Features\n",
    "This step replicates the operation performed in the ``api_data`` overview, by unpickling ``genre``,``style``,``label`` and ``formats``\n",
    "#### Step 4 - Clean Features with Multiple Categorical Values per Sample and High Categorical Variance\n",
    "For the features ``label`` and ``artist``, it quickly becomes clear that a more sophisticated approach is necessary than just simply One-Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Decca, The Compo Company Ltd.]</td>\n",
       "      <td>Bing Crosby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Decca]</td>\n",
       "      <td>Bing Crosby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Swing Classic, RCA Victor]</td>\n",
       "      <td>Tommy Dorsey And His Clambake Seven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Victor]</td>\n",
       "      <td>Paul Whiteman And His Orchestra, Bix Beiderbec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Decca, Decca Records, Inc.]</td>\n",
       "      <td>Jimmie Lunceford And His Orchestra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448897</th>\n",
       "      <td>[Production Dessinée, Disques Dessinee Distrib...</td>\n",
       "      <td>Mateo Stoneman = マテオ・ストーンマン*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448898</th>\n",
       "      <td>[Nailuj Music, Rebel Road Studio, San Diego, R...</td>\n",
       "      <td>Julian Juno*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448899</th>\n",
       "      <td>[Rubber Frog Records]</td>\n",
       "      <td>DJ Nonstick Cookware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448900</th>\n",
       "      <td>[Not On Label]</td>\n",
       "      <td>Papaw (2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448901</th>\n",
       "      <td>[Not On Label (Shady Monk Self-Released)]</td>\n",
       "      <td>Shady Monk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448902 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    label  \\\n",
       "0                         [Decca, The Compo Company Ltd.]   \n",
       "1                                                 [Decca]   \n",
       "2                             [Swing Classic, RCA Victor]   \n",
       "3                                                [Victor]   \n",
       "4                            [Decca, Decca Records, Inc.]   \n",
       "...                                                   ...   \n",
       "448897  [Production Dessinée, Disques Dessinee Distrib...   \n",
       "448898  [Nailuj Music, Rebel Road Studio, San Diego, R...   \n",
       "448899                              [Rubber Frog Records]   \n",
       "448900                                     [Not On Label]   \n",
       "448901          [Not On Label (Shady Monk Self-Released)]   \n",
       "\n",
       "                                                   artist  \n",
       "0                                             Bing Crosby  \n",
       "1                                             Bing Crosby  \n",
       "2                     Tommy Dorsey And His Clambake Seven  \n",
       "3       Paul Whiteman And His Orchestra, Bix Beiderbec...  \n",
       "4                      Jimmie Lunceford And His Orchestra  \n",
       "...                                                   ...  \n",
       "448897                       Mateo Stoneman = マテオ・ストーンマン*  \n",
       "448898                                       Julian Juno*  \n",
       "448899                               DJ Nonstick Cookware  \n",
       "448900                                          Papaw (2)  \n",
       "448901                                         Shady Monk  \n",
       "\n",
       "[448902 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_artist_columns = api_pipe.steps[2][-1].fit_transform(api_pipe.steps[1][-1].fit_transform(api_data)).loc[:,['label','artist']]\n",
    "label_artist_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us identify the number of unique values for each of these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The api_data dataset has 113842 unique label values\n",
      "The api_data dataset has 108872 unique artist values\n"
     ]
    }
   ],
   "source": [
    "label_values = label_artist_columns.loc[:,'label'].apply(lambda x: 'üü'.join(x)).str.split('üü',expand=True).stack()\n",
    "artist_values = label_artist_columns.loc[:,'artist']\n",
    "for values, column in zip((label_values,artist_values),('label','artist')):\n",
    "    print('The api_data dataset has %s unique %s values' % (len(np.unique(values)),column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the output above, the order of magnitude of unique values for these columns prevents us from taking the standard approach in machine learning of One-Hot Encoding these columns. Let us now see if there is any possibility of reducing the number of unique values and if there the elements can be unified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Blue Note', 17001),\n",
       " ('Columbia', 14162),\n",
       " ('Verve Records', 11287),\n",
       " ('Capitol Records', 9553),\n",
       " ('Van Gelder Studio, Englewood Cliffs, New Jersey', 9435),\n",
       " ('Atlantic', 8867),\n",
       " ('Not On Label', 8331),\n",
       " ('Capitol Records, Inc.', 7774),\n",
       " ('CBS', 7333),\n",
       " ('ECM Records', 7126),\n",
       " ('Prestige', 6943),\n",
       " ('CBS Inc.', 6862),\n",
       " ('RCA Victor', 6329),\n",
       " ('Warner Bros. Records', 6156),\n",
       " ('A&M Records', 5958),\n",
       " ('Polydor', 5681),\n",
       " ('Atlantic Recording Corporation', 5614),\n",
       " ('Impulse!', 5118),\n",
       " ('Universal Music LLC', 5089),\n",
       " ('EMI', 4933)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(label_values).most_common(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can clearly see that labels have been entered under slightly different names in some cases, in particular for the  following pairs:\n",
    "- Capitol Records & Capitol Records, Inc.\n",
    "- CBS & CBS Inc.\n",
    "Unifying these would by themselves already greatly increase the number of connected entries by homogenizing the names of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Various', 7248),\n",
       " ('Miles Davis', 2986),\n",
       " ('John Coltrane', 2071),\n",
       " ('Frank Sinatra', 2056),\n",
       " ('Sonny Rollins', 1242),\n",
       " ('Herbie Hancock', 1124),\n",
       " ('Ella Fitzgerald', 987),\n",
       " ('The Dave Brubeck Quartet', 948),\n",
       " ('George Benson', 868),\n",
       " ('Duke Ellington', 823),\n",
       " ('Nina Simone', 822),\n",
       " ('Charles Mingus', 806),\n",
       " ('Freddie Hubbard', 758),\n",
       " ('Jimmy Smith', 745),\n",
       " ('Herbie Mann', 732),\n",
       " ('Sarah Vaughan', 698),\n",
       " ('Chet Baker', 682),\n",
       " ('Keith Jarrett', 681),\n",
       " ('Frank Zappa', 647),\n",
       " ('Thelonious Monk', 646)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(artist_values).most_common(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of artists, it is not as clear that such cleaning would be required in order to get widespread connection between records, however, by taking a look at all entries containing 'Miles Davis', for example, we quickly observe in how many varied ways Miles Davis appears in the ``artist`` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Fats Navarro / Dizzy Gillespie / Miles Davis / Kenny Dorham',\n",
       " 'Miles Davis',\n",
       " 'Miles Davis With Sonny Rollins',\n",
       " 'Miles Davis Quartet*',\n",
       " 'Miles Davis And Milt Jackson',\n",
       " 'The New Miles Davis Quintet*',\n",
       " 'The Miles Davis Quintet',\n",
       " 'Miles Davis + 19, Gil Evans',\n",
       " 'Miles Davis + 19',\n",
       " 'Miles Davis, Gil Evans',\n",
       " 'Miles Davis Et Son Quintette*',\n",
       " 'Miles Davis All Stars',\n",
       " 'Michel Legrand Featuring Miles Davis',\n",
       " 'Miles Davis, Sonny Rollins',\n",
       " 'Miles Davis And The Modern Jazz Giants',\n",
       " 'Cannonball Adderley, Miles Davis, Hank Jones, Sam Jones, Art Blakey',\n",
       " 'Miles Davis Quintet*',\n",
       " 'Miles Davis Sextet*',\n",
       " 'Miles Davis , Arranged And Condusted By Gil Evans',\n",
       " 'The Miles Davis Sextet & The Thelonious Monk Quartet',\n",
       " 'Miles Davis & The Modern Jazz Giants',\n",
       " 'Miles Davis + 19 Orchestra Under The Direction Of Gil Evans',\n",
       " 'Sarah Vaughan With The Miles Davis All-Stars*',\n",
       " 'The Miles Davis Quintet Featuring John Coltrane',\n",
       " 'The Miles Davis Sextet And Quintet* Featuring: John Coltrane, Bill Evans',\n",
       " 'Miles Davis*',\n",
       " 'Sarah Vaughan With Miles Davis All Stars',\n",
       " 'Miles Davis  / Orchestra Under The Direction Of  Gil Evans, George Gershwin',\n",
       " 'The Miles Davis Sextet / The Miles Davis Quintet',\n",
       " 'Miles Davis Arranged And Conducted By Gil Evans',\n",
       " 'Miles Davis And His Orchestra',\n",
       " 'Miles Davis = マイルス・デイビス*',\n",
       " 'The Miles Davis Sextet',\n",
       " 'Cannonball Adderley with Miles Davis, Sam Jones, Hank Jones, Art Blakey',\n",
       " 'Miles Davis Featuring Sonny Rollins',\n",
       " 'The Miles Davis Quintet / Art Blakey And The Jazz Messengers*',\n",
       " 'Miles Davis With Gil Evans And His 21-Piece Orchestra*',\n",
       " 'Miles Davis-Tadd Dameron Quintet',\n",
       " 'The Miles Davis/Tadd Dameron Quintet*',\n",
       " 'The Miles Davis Sextet Featuring John Coltrane And \"Cannonball\" Adderley* / The Thelonious Monk Quartet And Pee Wee Russell',\n",
       " 'Miles Davis Sexteto*',\n",
       " 'Miles Davis, Jamey Aebersold',\n",
       " 'Jimmy Forrest / Miles Davis',\n",
       " 'Miles Davis / Jimmy Forrest',\n",
       " 'Miles Davis And The The Lighthouse All-Stars*',\n",
       " 'Miles Davis And The Lighthouse All-Stars*',\n",
       " 'Miles Davis & John Coltrane',\n",
       " 'Miles Davis, John Coltrane',\n",
       " 'Miles Davis And Sonny Stitt',\n",
       " 'Miles Davis + 19 , Orchestra Under The Direction Of Gil Evans',\n",
       " 'Miles Davis And  The Modern Jazz Giants',\n",
       " 'Miles Davis & Marcus Miller',\n",
       " 'Miles Davis ~ Marcus Miller',\n",
       " 'Miles Davis / Marcus Miller',\n",
       " 'Miles Davis With Orchestra Under The Direction Of Gil Evans*',\n",
       " 'Miles Davis / Sonny Stitt',\n",
       " 'Charlie Parker With  Miles Davis, Dizzy Gillespie, Max Roach, Lennie Tristano',\n",
       " 'Charlie Parker With Miles Davis, Dizzy Gillespie, Max Roach, Lennie Tristano',\n",
       " 'Miles Davis & Michel Legrand',\n",
       " 'Hi-Hat All-Stars, Miles Davis',\n",
       " 'Miles Davis Quintet* = マイルス・デイビス*',\n",
       " 'Sting & Jill Evans* . Miles Davis',\n",
       " 'Miles Davis & Quincy Jones',\n",
       " 'Miles Davis With Hank Mobley, Wynton Kelly, Paul Chambers (3), Jimmy Cobb',\n",
       " 'Miles Davis And The Gil Evans Orchestra*',\n",
       " 'Lee Konitz & Miles Davis / Teddy Charles & Jimmy Raney',\n",
       " 'Miles Davis / Miles Davis All Stars',\n",
       " 'Miles Davis / Gil Evans',\n",
       " 'The Miles Davis Quartet',\n",
       " 'Miles Davis & Charlie Parker',\n",
       " 'Charlie Parker & Miles Davis',\n",
       " 'Miles Davis / Stan Getz',\n",
       " 'Miles Davis All Stars / マイルス・デイヴィス*',\n",
       " 'Miles Davis . Gil Evans',\n",
       " 'Miles Davis & Gil Evans',\n",
       " 'Miles Davis, Stan Getz',\n",
       " 'Miles Davis & Jimmy Forrest',\n",
       " 'Miles Davis Quintet* Featuring John Coltrane',\n",
       " 'Miles Davis Quintet* Featuring Barney Wilen',\n",
       " 'Miles Davis Quintet* With John Coltrane',\n",
       " 'Miles Davis All Stars = マイルス・デイヴィス*',\n",
       " 'The Miles Davis Quintet Featuring John Coltrane │ Red Garland │ \"Philly\" Joe Jones │ Paul Chambers (3)',\n",
       " 'Miles Davis + 19 Orchestra Under Direction Of Gil Evans',\n",
       " 'Michel Legrand & Miles Davis',\n",
       " 'Miles Davis  Featuring  Barney Wilen',\n",
       " 'Cannonball Adderley & Miles Davis',\n",
       " 'Miles Davis Quintet* Together With Gil Evans Orchestra*',\n",
       " 'Miles Davis & Robert Glasper',\n",
       " 'The Miles Davis Sextet, Duke Ellington And His Orchestra',\n",
       " 'Miles Davis, Milt Jackson',\n",
       " 'Miles Davis  &  John Coltrane',\n",
       " 'Miles Davis Octet',\n",
       " 'マイルス・デイビス* = Miles Davis x ロバート・グラスパー* = Robert Glasper',\n",
       " 'Cannonball Adderley, Miles Davis',\n",
       " 'The Miles Davis Quintet, John Coltrane',\n",
       " 'Stan Getz And Miles Davis')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miles_davis_values = tuple(filter(lambda x: 'miles davis' in x.lower(), Counter(artist_values)))\n",
    "miles_davis_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, in order to reduce the dimensionality and increase the linkages between different jazz albums, it will also be crucial to clean the ``artist`` column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve this, we apply the ``ArtistCleanReduce`` and ``LabelCleanReduce`` transformers, which clean and homogenize the text inputs, and match the resulting unique strings with one another using TF-IDF Vectorization with ngrams. In the case of ``LabelCleanReduce``, we pick the first unique element attributed to an entry, as it is deemed to be the most relevant label for the release. For both the ``artist`` and ``label`` columns, this results in a great reduction in the cardinality of entries associated with both columns, as we can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = clean_text_pipe.fit_transform(label_artist_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ('label','artist'):\n",
    "    print('The cleaned api_data has %s unique %s values' % (len(np.unique(cleaned_text.loc[:,column])),column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Namespace Cleanup\n",
    "del label_artist_columns,label_values,artist_values,miles_davis_values,cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5 - Remove Entries with Duplicate ``release_ids``\n",
    "The results obtained from querying the Discogs.com API yielded a substantial number of duplicates for the ``release_id`` feature, as we can see from the cell below. As this is a unique identifier for each album, we will remove those entries for which a duplicate ``release_id`` is identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of entries with duplicated release_id values is:',len(api_data[api_data['release_id'].duplicated()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6 - Encode Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the ``column_encoding_pipe``, we turn our attention to the encoding of the ``country``, ``genre`` and ``style`` columns shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = Unpickler(['genre','style']).fit_transform(api_data.loc[:,['country','genre','style']])\n",
    "categorical_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the output above, we have two different encodings, as in the ``clean_text_pipe``. The ``country`` column is of a string type, whereas the ``genre`` and ``style`` features contain list-type values for each sample. It is important to know that the ``country`` attribute is provided by users themselves, whereas the ``genre`` and ``style`` values are set by Discogs and are thus more standardized\n",
    "\n",
    "As such, for the ``genre`` and ``style`` columns, we simply need to utilize dummy encoding in order to encode the information from these features. We do this by implementing and extending the ``MultiValueCategoricalEncoder`` class which encodes the features accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.transformers import MultiValueCategoricalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_genre_style = MultiValueCategoricalEncoder('style')\\\n",
    "    .fit_transform(\n",
    "        GenreEncoder()\\\n",
    "            .fit_transform(categorical_features)\n",
    ")\n",
    "encoded_genre_style.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with the ``country`` feature, we take a different approach. As each country associated with a given sample contains information related to the broader region of the globe the album comes from, we implement a custom transformer called ``CountryEncoder``, which reads in the string input of the ``country`` feature, and dummy encodes the information according to which countries the album comes from, and additionally add columns outlining the regions and superregions the album release belongs to. In this case, regions refer to the the UN Geoschemes according to their M49 classification code. Superregions are used to refer to the following regions which supersede and contain within them the UN Geoscheme regions:\n",
    "- Africa\n",
    "- Americas\n",
    "- Asia\n",
    "- Europe\n",
    "- Oceania\n",
    "- Unknown (in case of missing information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountryEncoder().fit_transform(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del categorical_features, encoded_genre_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7 - Create and Encode Format Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step, we must decompose the formats column such it is interpretable for our machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unpickler('formats').fit_transform(api_data)['formats']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``formats`` column is saved in a dictionary type, which means that we must extract the value of each key of the dictionaries and create a new independent feature. We do this via the ``FormatEncoder`` transformer, which executes this for the four keys that are found throughout the feature, and creates the columns ``format_description``, ``format_text``,``format_name``, ``format_quantity``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formats = FormatEncoder().fit_transform(Unpickler('formats').fit_transform(api_data))[['format_name','format_quantity','format_text','format_description']]\n",
    "formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the above features, we have two fairly cleanly formatted ones in ``format_name`` and ``format_quantity``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formats['format_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(formats['format_quantity'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we can see from the range of values in ``format_name`` that we require no additional encoding other than One-Hot encoding prior to estimation at this stage, we see that there is a fairly long tail in the quantity of units that are associated with each album. In order to avoid these outliers from negatively impacting our predictions, we use the ``OutlierRemover`` transformer which removes values that are more than three standard deviations removed from the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(OutlierRemover('format_quantity').fit_transform(formats)['format_quantity'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the ``format_text``and ``format_description`` features, we utilize similar approaches as in previous sections, due to similar issues occuring in the data. For ``format_text``, we extend the ``FeatureCleanReduce`` transformer to create the ``FormatTextCleanReduce`` transformer in order to reduce the feature's cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(formats['format_text'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FormatTextCleanReduce().fit_transform(formats)['format_text'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the cardinality of the feature is still fairly high, we will forego dummy encoding at this point and use a label encoding approach similar to the artist and label columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the ``format_description`` column, we observe that there is a more standardized set of values for the feature, and as such we can simply apply the ``MultiValueCategoricalEncoder`` as in previous sections for features with list datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiValueCategoricalEncoder('format_description').fit_transform(formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8 - Create and Encode Time Period Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an additional step of feature engineering, we will utilize the ``year`` feature to encode some information about the distinct eras taking place in the history of Jazz music. This information is obtained from online sources, and encodes the following time periods and eras:\n",
    "- Eras\n",
    "    - Swing (1925 - 1945)\n",
    "    - Modern (1940 - 1970)\n",
    "    - Contemporary (1970 - 2020)\n",
    "- Periods\n",
    "    - Big Band (1930 - 1950)\n",
    "    - Bebop (1940 - 1955)\n",
    "    - Cool (1950 - 1970)\n",
    "    - Fusion (1970 - 2020)\n",
    "        - Dropped because it coincides exactly with the contemporary era\n",
    "This simple dummy encoding of the time period incidence is achieved using the ``TimePeriodEncoder`` transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimePeriodEncoder().fit_transform(api_data)[[\n",
    "    'year','era_modern','era_contemporary','era_swing',\n",
    "    'period_big_band','period_bebop','period_cool'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesis\n",
    "All in all, we combine these steps through the ``api_pipe``, which yields the following output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_pipe.fit_transform(api_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracted Data\n",
    "### Loading and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_from_pkl('extracted',path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unpickler('track_titles').fit_transform(extracted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``extracted_data`` DataFrame represents the data that was obtained from scraping Discogs.com release pages for the albums which were obtained through the initial querying of their API. This data is crucial in being able to build the model estimating the market value of jazz albums, as no price information is divulged by the API, and can only be programmatically obtained through web scraping. Additionally, the release pages for albums on Discogs are additionally informative in that they provide platform-specific metadata which can ultimately be used in predicting market value in the previously outlined full-information scenario. \n",
    "\n",
    "What follows is a description of each variable and its relevance to the project:\n",
    "- ``release_id``\n",
    "    - As for the ``api_data``, the release_id is the unique identifier for each album release and will form the primary key with which we can later join our data sources\n",
    "- ``market_price``\n",
    "    - This feature reflects the lowest price at which a given album release is available for on the Discogs.com platform. Releases which have no open listings on the platform have null values\n",
    "- ``units_for_sale``\n",
    "    - This feature outlines how many units of the album release are available on the Discogs.com platform\n",
    "- ``average_rating``\n",
    "    - Here the mean score out of 5 attributed to the album release by Discogs.com users is recorded\n",
    "- ``rating_count``\n",
    "    - Records the number of ratings that have been submitted for the album release\n",
    "- ``last_sold``\n",
    "    - Records the last time the album release was sold on the Discogs.com platform\n",
    "- ``number_of_tracks``\n",
    "    - This feature was generated through the process of scraping, and counts the total number of tracks that are listed for an album release\n",
    "- ``running_time``\n",
    "    - Like the previous feature, this one was also generated during scraping, and records the total ``running_time`` of the album in minutes\n",
    "- ``lowest``, ``median``, ``highest``\n",
    "    - These three features record the lowest, median and highest prices each album was sold for on the platform. \n",
    "- ``track_titles``\n",
    "    - Here all the track titles of the record are recorded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Pipeline\n",
    "As for ``api_data``, we will replicate the transformation pipeline used to process the data scraped from Discogs.com release pages and go motivate each step of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.transformers import (\n",
    "    ColumnRemover,\n",
    "    ColumnCombiner,\n",
    "    DuplicateRemover,\n",
    "    NullRemover,\n",
    "    StandardCountEncoder,\n",
    "    LastSoldEncoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_value_pipe =  Pipeline([\n",
    "    #Step 3a - Creating market_value by imputing median nulls with market_price values\n",
    "    ('make_market_value', ColumnCombiner('median','market_price','market_value')),\n",
    "    #Step 3b - Removing samples with null values for market_value\n",
    "    ('remove_nulls', NullRemover('market_value')),\n",
    "    #Step 3c - Removing samples with outlier values for market_value according to 3 standard deviation rule\n",
    "    ('remove_outliers', OutlierRemover('market_value'))\n",
    "])\n",
    "\n",
    "extracted_pipe = Pipeline([\n",
    "    #Step 1 - Remove unnecessary columns\n",
    "    ('remove_id', ColumnRemover(['id','last_sold'])),\n",
    "    #Step 2 - Unpickle the track_titles features\n",
    "    ('unpickle', Unpickler('track_titles')),\n",
    "    #Step 3 - Creating and process the ``market_value`` feature\n",
    "    ('make_market_value',market_value_pipe),\n",
    "    #Step 4 - Remove any duplicates present in the release_id feature\n",
    "    ('remove_duplicates', DuplicateRemover('release_id')),\n",
    "    #Step 5 - Count the number of Jazz standards each album has\n",
    "    ('count_standards',StandardCountEncoder('track_titles',DATA_PATH))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparison to the ``api_data`` DataFrame, the ``extracted_data`` DataFrame is far less unwieldy and messy, and instead requires only small adjustments to be made to the core features, as well as some additional transformations for feature engineering purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - Removing unnecessary features\n",
    "We decide to remove the ``last_sold`` feature due to it having an untenable number of null values, and due to the high variation in the ranges in which albums have last been sold for the albums in question, the missing values cannot be imputed in good conscience. As such, the feature is dropped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data['last_sold'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Unpickling ``track_titles``\n",
    "Self-explanatory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Creating & processing the ``market_value`` feature\n",
    "As outlined previously, we have two features in the ``extracted_data`` dataset that could conceivably be used as the dependent variable in our machine learning model to predict the market value of a given Jazz album, namely ``market_price`` and ``median``. Without missing data, it would be preferable to use the ``median`` price for the ``market_value`` of a given record, as the value of ``market_price`` is contingent on the period in which the data was scraped and may not be an accurate representation of what price the album is generally valued at in the market. Furthermore, as the ``market_price`` is the lowest price that a given record is being sold for, it could be that the reason for the price being so low is due to the poor quality of the record, a feature which is not captured in our data but is available in separate listings view of the record, which has been left out of the scope of this project in the interest of time, as it would have required the scraping another 350k web requests to the Discogs.com servers. \n",
    "However, as we can see below, we do not have access to the ``median`` price for around 150,000 albums, and as such a sole reliance on this attribute would mean we would no longer be able to incorporate these albums in our analysis. In order to minimize the amount of data that must be discarded, we take the approach of combining the ``market_price`` and ``median`` features by filling the missing values of ``median`` with the values of ``market_price``. The rationale behind this combination of features is that a missing value for ``median_price`` indicates that the album in question has never been sold on the Discogs.com platform. Why this is the case could be down to a number of reasons, such as the album being fairly niche, new on the market or not particularly popular among the types of users that Discogs.com attracts. As such, we can noisily impute the value of the record by the supply-side valuation of the album in order to reduce the number of samples that must be removed from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data.loc[:,['market_price','median']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_value_features = ColumnCombiner('median','market_price','market_value').fit_transform(extracted_data).loc[:,['market_value','median','market_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_value_features.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above, post-imputation it is possible to keep around 100,000 samples in the dataset for training our machine learning models. Nevertheless, we must still remove the entries for which ``market_value`` is null, as well as those samples that have outlier values, which we achieve using the ``NullRemover`` and ``OutlierRemover`` transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutlierRemover('market_value').fit_transform(\n",
    "    NullRemover('market_value').fit_transform(\n",
    "        market_value_features\n",
    "    )\n",
    ").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the output above, by removing the nulls and outliers from the ``market_value`` feature, we manage to obtain a very similar distribution to the ``median`` feature we would have otherwise preferred from the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del market_value_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 - Removing Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the processing of ``api_data``, it is critical that we discard the duplicate values of ``release_id`` in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of duplicates is: ',len(extracted_data)-len(DuplicateRemover('release_id').fit_transform(extracted_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5 - Count number of standards per Jazz album\n",
    "In an attempt to inject our data with some additional domain knowledge, we will analyze the ``track_titles`` feature of the ``extracted_data`` DataFrame and seek to identify the number of Jazz standards that each album has on its tracklist. Jazz Standards are pieces of music which are commonly covered by artists within the Jazz community, and provide a possible entrypoint of prospective customers to purchasing the record, as they may be more likely to recognize a certain track on a record, and therefore be more incentivized to buy it. Generally, audiences enjoy hearing another artist's take on an old classic, which makes this feature of Jazz music culture a possibly informative feature to be added for our modelling. \n",
    "We accomplish this via a similar method as was employed in the ``FeatureCleanReduce`` inheriting estimators, by using TF-IDF with n-grams in order to compare the ``track_titles`` for each album with an independently sourced list of accepted jazz standards, and attempting to find high prbability matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standards = StandardCountEncoder(path=DATA_PATH).fit_transform(\n",
    "    Unpickler('track_titles').fit_transform(extracted_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del standards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Level Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(os.path.join(DATA_PATH,'high_level_features.npz')) as file:\n",
    "    high_level_features = pd.DataFrame(file['data'].reshape(1,-1))\n",
    "    \n",
    "    high_level_features['release_id'] = file['label'].reshape(1,-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_level_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = extracted_pipe.fit_transform(extracted_data)\n",
    "extracted_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data = api_pipe.fit_transform(api_data)\n",
    "api_data.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
