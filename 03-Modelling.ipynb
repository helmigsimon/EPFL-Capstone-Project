{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 - Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional - Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restart_runtime():\n",
    "    os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_rapids():\n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "    device_name = pynvml.nvmlDeviceGetName(handle)\n",
    "    if (device_name != b'Tesla T4') and (device_name != b'Tesla P4') and (device_name != b'Tesla P100-PCIE-16GB'):\n",
    "        print(\"Wrong GPU - Restarting Runtime\")\n",
    "        restart_runtime()\n",
    "\n",
    "\n",
    "    # clone RAPIDS AI rapidsai-csp-utils scripts repo\n",
    "    !git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
    "\n",
    "    # install RAPIDS\n",
    "    !bash rapidsai-csp-utils/colab/rapids-colab.sh 0.13\n",
    "\n",
    "\n",
    "    # set necessary environment variables \n",
    "    dist_package_index = sys.path.index('/usr/local/lib/python3.6/dist-packages')\n",
    "    sys.path = sys.path[:dist_package_index] + ['/usr/local/lib/python3.6/site-packages'] + sys.path[dist_package_index:]\n",
    "    sys.path\n",
    "\n",
    "    # update pyarrow & modules \n",
    "    exec(open('rapidsai-csp-utils/colab/update_modules.py').read(), globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_conda():\n",
    "    if not 'Miniconda3-4.5.4-Linux-x86_64.sh' in os.listdir():\n",
    "        !wget https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh && bash Miniconda3-4.5.4-Linux-x86_64.sh -bfp /usr/local\n",
    "\n",
    "    if not ('EPFL-Capstone-Project' in os.listdir()) and (os.getcwd().split('/')[-1] != 'EPFL-Capstone-Project'):\n",
    "        !git clone https://github.com/helmigsimon/EPFL-Capstone-Project  \n",
    "    os.chdir('EPFL-Capstone-Project')\n",
    "\n",
    "    !conda env create -f environment.yml\n",
    "    !conda activate exts-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_drive():\n",
    "    #Mounting Google Drive\n",
    "    global drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import sys,os\n",
    "    \n",
    "    setup_drive()\n",
    "\n",
    "    #Setting up PyPi Packages\n",
    "    !pip install geopandas sparse-dot-topn pdpipe \n",
    "    import geopandas as gpd\n",
    "    import sparse_dot_topn.sparse_dot_topn as ct\n",
    "    import pdpipe as pdp\n",
    "\n",
    "    #Setting up Conda Packages\n",
    "    setup_conda()\n",
    "    \n",
    "    #Initializing NLTK\n",
    "    import nltk\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('punkt')\n",
    "    \n",
    "    #Setting up RAPIDS AI\n",
    "    import pynvml\n",
    "    setup_rapids()\n",
    "    \n",
    "    from cuml import UMAP\n",
    "    \n",
    "except ModuleNotFoundError as e:\n",
    "    print(e)\n",
    "    print('Not in colab environment, continuing to run locally')\n",
    "    from umap import UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split,  StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.transformers import RunningTimeImputer, ColumnRemover\n",
    "from lib.processing import save_to_pkl, load_from_pkl\n",
    "from data.util.paths import DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.leave_one_out import LeaveOneOutEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_df = load_from_pkl('api')\n",
    "extracted_df = load_from_pkl('extracted')\n",
    "with np.load(os.path.join(DATA_PATH,'high_level_features_labelled.npz')) as data:\n",
    "    image_embedding_df = pd.concat([pd.DataFrame(data[section]) for section in ('release_id','bitmap','features')],axis=1)\n",
    "    image_embedding_df.columns = ['release_id', 'bitmap'] + ['feature_%s' % i for i in range(1,1281)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Dimensionality of Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "umap = UMAP(n_components=10)\n",
    "image_embeddings_scaled = scaler.fit_transform(image_embedding_df.loc[:,sorted(list(column_store._image_embedding))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('release_id',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(df.drop('market_value',axis=1),df.market_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the above columns, we will only handl ``running_time``, ``average_rating`` and ``units_for_sale``. The rest will not be necessary to handle for the purposes of the models we plan on building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_information_transformer = ColumnTransformer(transformers=[\n",
    "    ('units_for_sale_imputer', SimpleImputer(strategy='constant',fill_value=0),['units_for_sale']),\n",
    "    ('average_rating_imputer', SimpleImputer(strategy='mean'),['average_rating']),\n",
    "    ('year_encoder', OneHotEncoder(dtype=np.uint8), ['year'])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_store_transformer = ColumnTransformer(transformers=[\n",
    "    ('year_encoder', OneHotEncoder(dtype=np.uint8), ['year'])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_store_ridge_removal_columns = [\n",
    "    'market_price','units_for_sale','have','want','average_rating','rating_count','last_sold','lowest','median',\n",
    "    'highest','track_titles','country','genre','style','label','community_have','community_want','formats','master_id','thumb_url',\n",
    "    'release_url','artist','title','format_description','format_text_clean','format_text', 'no_of_days_since_last_sale'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_store_ridge_param_grid = dict(ridge__alpha=np.linspace(900,1000,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_store_ridge_pipe = Pipeline([\n",
    "    ('running_time_imputer',RunningTimeImputer('running_time','number_of_tracks')),\n",
    "    ('leave_one_out_encoding', LeaveOneOutEncoder(cols=['artist_clean','label_clean'])),\n",
    "    ('record_store_column_remover', ColumnRemover(record_store_ridge_removal_columns)),\n",
    "    ('preprocessing',record_store_transformer),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', GridSearchCV(\n",
    "        SGDRegressor(\n",
    "            early_stopping=True,\n",
    "            max_iter=1000,\n",
    "            tol=0.001,\n",
    "            n_iter_no_change=5,\n",
    "            verbose=1\n",
    "        ),\n",
    "        param_grid=record_store_ridge_param_grid,\n",
    "        cv=5\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_store_ridge_pipe.fit(X_tr,np.log(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_store_ridge_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_store_ridge_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pred = record_store_ridge_grid_search.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(np.log(y_te),np.exp(ridge_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(np.log(y_te),np.exp(ridge_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_param_grid = {\n",
    "    'n_estimators': tuple(range(50,350,50)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_pipe = Pipeline([\n",
    "    ('running_time_imputer',RunningTimeImputer('running_time','number_of_tracks')),\n",
    "    ('leave_one_out_encoding', LeaveOneOutEncoder(cols=['artist_clean','label_clean'])),\n",
    "    ('record_store_column_remover', ColumnRemover(record_store_ridge_removal_columns)),\n",
    "    ('preprocessing',record_store_transformer),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('random_forest', GridSearchCV(\n",
    "        RandomForestRegressor(\n",
    "            random_state=0,\n",
    "            n_jobs=-1,\n",
    "            criterion='mae',\n",
    "            verbose=50\n",
    "        ),\n",
    "        cv=5,\n",
    "        param_grid=random_forest_param_grid,\n",
    "        verbose=50\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_pipe.fit(X_tr,np.log(y_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extremely Randomized Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_trees_pipe = Pipeline([\n",
    "    ('running_time_imputer',RunningTimeImputer('running_time','number_of_tracks')),\n",
    "    ('leave_one_out_encoding', LeaveOneOutEncoder(cols=['artist_clean','label_clean'])),\n",
    "    ('record_store_column_remover', ColumnRemover(record_store_ridge_removal_columns)),\n",
    "    ('preprocessing',record_store_transformer),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('random_forest', GridSearchCV(\n",
    "        ExtraTreesRegressor(\n",
    "            random_state=0,\n",
    "            n_jobs=4,\n",
    "            verbose=50\n",
    "        ),\n",
    "        param_grid=random_forest_param_grid,\n",
    "        verbose=50\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_trees_pipe.fit(X_tr,np.log(y_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_store_catboost_removal_columns = (\n",
    "    'market_price','units_for_sale','have','want','average_rating','rating_count','last_sold','lowest','median',\n",
    "    'highest','track_titles','community_have','community_want','formats','master_id','thumb_url',\n",
    "    'release_url','artist','title','format_description','format_text_clean', 'no_of_days_since_last_sale'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_param_grid = {\n",
    "        'depth': [4,7,10],\n",
    "        'learning_rate' : np.logspace(-4,-1,5),\n",
    "        'l2_leaf_reg': [1,4,9],\n",
    "        'iterations': [100,300,500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_pipe = Pipeline([\n",
    "    ('running_time_imputer',RunningTimeImputer('running_time','number_of_tracks')),\n",
    "    ('leave_one_out_encoding', LeaveOneOutEncoder(cols=['artist_clean','label_clean'])),\n",
    "    ('record_store_column_remover', ColumnRemover(record_store_catboost_removal_columns)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('grid_search', GridSearchCV(\n",
    "        CatBoostRegressor(\n",
    "            random_state=0,\n",
    "            cat_features=['year','format_text']),\n",
    "        param_grid=catboost_param_grid,verbose=5)\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_pipe.fit(X_tr,np.log(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
