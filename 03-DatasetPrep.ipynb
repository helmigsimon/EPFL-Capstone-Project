{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "buFUSHKt8apx"
   },
   "source": [
    "# 03 - Dataset Preparation\n",
    "In order to streamline the process of training and evaluating the machine learning models that we will build in the following Notebook, ``04-Modelling``, we use the pipelines developed in the previous notebooks in order to create the core `metadata_df` and `image_embeddings_df` datasets which will be saved in .pkl format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YsMW-elZopc_"
   },
   "source": [
    "## Setting up Colab Environment if in Colab\n",
    "A key component of the processing of our data will involve the dimensionality reduction of the high-level features of the image data we have obtained using the pre-trained MobileNetV2 Model introduced in the previous notebook. Due to the high dimensionality and cardinality of our data, and our choice of the UMAP algorithm as the dimensionality reduction tool of choice in this project, we will make use of the RAPIDS AI CUML library (https://docs.rapids.ai/api), which provides a sci-kit learn-like API for implementations of machine learning algorithms that are specifically configured to run on GPU hardware. Using this library will significantly speed up the computation time associated with the dimensionality reduction we conduct towards the end of this notebook.\n",
    "\n",
    "As I do not personally have access to a GPU, the GPU-enabled part of this notebook is run on Google's Colab Notebook environment, which offers GPU access for free. In the cell belows below, we define the functions required to setup a 25GB RAM Colab Notebook Environment with the packages necessary for the code to function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQQCreB5gAR_"
   },
   "outputs": [],
   "source": [
    "def upgrade_runtime_ram():\n",
    "    meminfo = subprocess.getoutput('cat /proc/meminfo').split('\\n')\n",
    "\n",
    "    memory_info = {entry.split(':')[0]: int(entry.split(':')[1].replace(' kB','').strip()) for entry in meminfo}\n",
    "\n",
    "    if memory_info['MemTotal'] > 17000000:\n",
    "        return\n",
    "\n",
    "    a = []\n",
    "    while(1):\n",
    "        a.append('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "waACZBi_8ap2"
   },
   "outputs": [],
   "source": [
    "def restart_runtime():\n",
    "    os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIsGqbsy8aqB"
   },
   "outputs": [],
   "source": [
    "def setup_rapids():\n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "    device_name = pynvml.nvmlDeviceGetName(handle)\n",
    "    if (device_name != b'Tesla T4') and (device_name != b'Tesla P4') and (device_name != b'Tesla P100-PCIE-16GB'):\n",
    "        print(\"Wrong GPU - Restarting Runtime\")\n",
    "        restart_runtime()\n",
    "\n",
    "\n",
    "    # clone RAPIDS AI rapidsai-csp-utils scripts repo\n",
    "    !git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
    "\n",
    "    # install RAPIDS\n",
    "    !bash rapidsai-csp-utils/colab/rapids-colab.sh 0.13\n",
    "\n",
    "\n",
    "    # set necessary environment variables \n",
    "    dist_package_index = sys.path.index('/usr/local/lib/python3.6/dist-packages')\n",
    "    sys.path = sys.path[:dist_package_index] + ['/usr/local/lib/python3.6/site-packages'] + sys.path[dist_package_index:]\n",
    "    sys.path\n",
    "\n",
    "    # update pyarrow & modules \n",
    "    exec(open('rapidsai-csp-utils/colab/update_modules.py').read(), globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9CcPvNIo8aqI"
   },
   "outputs": [],
   "source": [
    "def setup_conda():\n",
    "    if not 'Miniconda3-4.5.4-Linux-x86_64.sh' in os.listdir():\n",
    "        !wget https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh && bash Miniconda3-4.5.4-Linux-x86_64.sh -bfp /usr/local\n",
    "\n",
    "    if not ('EPFL-Capstone-Project' in os.listdir()) and (os.getcwd().split('/')[-1] != 'EPFL-Capstone-Project'):\n",
    "        !git clone https://github.com/helmigsimon/EPFL-Capstone-Project  \n",
    "    if 'EPFL-Capstone-Project' in os.listdir():\n",
    "        os.chdir('EPFL-Capstone-Project')\n",
    "\n",
    "    !conda env create -f environment.yml\n",
    "    !conda activate exts-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHSZ-lgE8aqP"
   },
   "outputs": [],
   "source": [
    "def setup_drive():\n",
    "    #Mounting Google Drive\n",
    "    global drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "N_uPJqb58aqW",
    "outputId": "42650701-19fc-4fd7-c5d6-fc9057b36c7e"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import sys,os,subprocess\n",
    "    \n",
    "    upgrade_runtime_ram()\n",
    "    setup_drive()\n",
    "\n",
    "    #Setting up PyPi Packages\n",
    "    !pip install geopandas sparse-dot-topn pdpipe category-encoders\n",
    "    import geopandas as gpd\n",
    "    import sparse_dot_topn.sparse_dot_topn as ct\n",
    "    import pdpipe as pdp\n",
    "    import category_encoders\n",
    "\n",
    "    #Setting up Conda Packages\n",
    "    setup_conda()\n",
    "    \n",
    "    #Initializing NLTK\n",
    "    import nltk\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('punkt')\n",
    "    \n",
    "    #Setting up RAPIDS AI\n",
    "    import pynvml\n",
    "    setup_rapids()\n",
    "    \n",
    "    from cuml import UMAP\n",
    "    \n",
    "except ModuleNotFoundError as e:\n",
    "    print(e)\n",
    "    print('Not in colab environment, continuing to run locally')\n",
    "    from umap import UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kvn45BG28aqd"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IRijjSry8aqf"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split,  StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fEgS7UQD8aqk"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u5KwAwAe8aqp"
   },
   "outputs": [],
   "source": [
    "from lib.transformers import *\n",
    "from lib.pipelines import *\n",
    "from lib.processing import save_to_pkl, load_from_pkl\n",
    "from data.util.paths import DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ixGjIOwS8aq1"
   },
   "outputs": [],
   "source": [
    "from category_encoders.leave_one_out import LeaveOneOutEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6jHrhZT8aq6"
   },
   "source": [
    "## DataFrame Setup\n",
    "### Creating the ``metadata_df`` DataFrame\n",
    "To avoid having to continuously apply the processing steps necessary to generate the core DataFrame we will use for building the models in this project, we generate our core DataFrames below. In the first step, we create the ``metadata_df`` DataFrame, which combines the data from the ``api_df`` and ``extracted_df`` DataFrames we have worked with in previous notebooks. On this data, we apply the ``api_pipe``, ``extracted_pipe`` and ``consolidation_pipe`` pipelines we have constructed using the data transformations outlined in the previous two notebooks. The result of these transformations is the ``metadata_df`` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpDf_3kT8aq7"
   },
   "outputs": [],
   "source": [
    "api_df = load_from_pkl('api',DATA_PATH)\n",
    "extracted_df = load_from_pkl('extracted',DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "70a9f8f848364b44a7f8ce3a0e38f0bc",
      "c239aa97d572423e8d1b3a6c40456735",
      "b6aa7508cf04481ebc903f59766b25bc",
      "64b72e6395d14ddf847c74a194fd3d7c",
      "59554c151c0d4283b244751356149e67",
      "8c57f4a8a5264df3a8c6b2013d7a798c",
      "fe068259cd254dca8f3ca86f8a0e597a",
      "d37e2d8dcd8a40d681f4536012442a10"
     ]
    },
    "colab_type": "code",
    "id": "iZP1t_evMdaG",
    "outputId": "184051ec-4ffd-4168-be0f-e5d301d4bfa1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd02f9879bd482cae5b93f9cc5afb50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "api_df = api_pipe.fit_transform(api_df)\n",
    "extracted_df = extracted_pipe.fit_transform(extracted_df)\n",
    "metadata_df = api_df.merge(extracted_df,how='inner',on='release_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7zRYsk69opeB"
   },
   "outputs": [],
   "source": [
    "col_set = {\n",
    "    'format': {\n",
    "        'description': 'format_description_', \n",
    "        'name': 'format_name_', \n",
    "        'text': ('format_text_clean'),\n",
    "        'quantity': ('format_quantity')\n",
    "    },\n",
    "    'geography': {\n",
    "        'superregion': 'superregion_',\n",
    "        'region': 'region_',\n",
    "        'country': 'country_'\n",
    "    },\n",
    "    'timeperiod': {\n",
    "        'period': 'period_',\n",
    "        'era': 'era_'\n",
    "    },\n",
    "    'genre': 'genre_',\n",
    "    'style': 'style_',\n",
    "    'null': None,\n",
    "    'indicator': lambda x: x.max() == 1 and x.min() == 0,\n",
    "}\n",
    "column_store = ColumnStore()\n",
    "column_store.fit(metadata_df,col_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 296157/296157 [00:24<00:00, 12155.53it/s]\n",
      "100%|██████████| 165777/165777 [00:00<00:00, 773462.86it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0d53a7b70e44818a8d39710662ebec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=908.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "consolidation_pipe = make_data_consolidation_pipe(metadata_df,column_store)\n",
    "metadata_df = consolidation_pipe.fit_transform(metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4ze91bms9_w"
   },
   "outputs": [],
   "source": [
    "save_to_pkl(metadata_df,'metadata',DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6n5farW8arB"
   },
   "source": [
    "### Creating the ``image_embeddings_df`` DataFrame\n",
    "As outlined in the previous notebook, we will be making use of the high-level features which have been extracted from the cover images available for the Jazz albums we are considering in this project, as a means to recreate the full experience of a Jazz album consumer when purchasing albums in the Record Store and Full Information scenarios. In what follows, we load the high-level features, and apply the UMAP dimensionality reduction algorithm to them, in order to obtain a lower dimensional representation of the visual information the albums encode, as input for our prediction algorithms. We reduce the dimensionality of the data from 1280, to 10 dimensions. The reason for this is the importance of being able to control dimensionality for input into our prediction algorithms, as well as the evidence outlined in the previous notebook, which indicates that the visual information the covers encode is not a strong predictor of Jazz album ``market_value``. Nonetheless, following from the framing of our problem, we elect to continue to include the features in the inputs we use to train our prediction algorithms.\n",
    "\n",
    "We save the results of this dimensionality reduction procedure to ``image_embeddings.pkl``, which we will then merge into our core DataFrame in the following notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hTNDpVXKMdVp"
   },
   "outputs": [],
   "source": [
    "with np.load(os.path.join(DATA_PATH,'high_level_features_labelled.npz')) as data:\n",
    "    high_level_feature_df = pd.concat([pd.DataFrame(data[section]) for section in ('release_id','bitmap','features')],axis=1)\n",
    "    high_level_feature_df.columns = ['release_id', 'bitmap'] + ['feature_%s' % i for i in range(1,1281)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vpYiYhDnmfDT"
   },
   "outputs": [],
   "source": [
    "from cuml import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46fQY6W28arC"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "umap = UMAP(n_components=10)\n",
    "high_level_features_df_scaled = scaler.fit_transform(high_level_feature_df.loc[:,['feature_%s' % i for i in range(1,1281)]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "-DiegN158q_u",
    "outputId": "43d12204-7474-4497-9a2a-1152e1f3f317"
   },
   "outputs": [],
   "source": [
    "image_embeddings_df = umap.fit_transform(high_level_features_df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9O2_hoRwzSio"
   },
   "outputs": [],
   "source": [
    "image_embeddings_df = pd.concat([\n",
    "      high_level_feature_df.loc[:,'release_id'],\n",
    "      pd.DataFrame(\n",
    "          image_embeddings_df,\n",
    "          columns = ['images_umap_%s' % i for i in range(image_embeddings_df.shape[1])]\n",
    "      )],\n",
    "      axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdOsgGs9c82j"
   },
   "outputs": [],
   "source": [
    "save_to_pkl(image_embeddings_df, 'image_embeddings',DATA_PATH)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "03-DatasetPrep.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "59554c151c0d4283b244751356149e67": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "64b72e6395d14ddf847c74a194fd3d7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d37e2d8dcd8a40d681f4536012442a10",
      "placeholder": "​",
      "style": "IPY_MODEL_fe068259cd254dca8f3ca86f8a0e597a",
      "value": " 899112/? [00:21&lt;00:00, 40943.17it/s]"
     }
    },
    "70a9f8f848364b44a7f8ce3a0e38f0bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b6aa7508cf04481ebc903f59766b25bc",
       "IPY_MODEL_64b72e6395d14ddf847c74a194fd3d7c"
      ],
      "layout": "IPY_MODEL_c239aa97d572423e8d1b3a6c40456735"
     }
    },
    "8c57f4a8a5264df3a8c6b2013d7a798c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6aa7508cf04481ebc903f59766b25bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c57f4a8a5264df3a8c6b2013d7a798c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_59554c151c0d4283b244751356149e67",
      "value": 1
     }
    },
    "c239aa97d572423e8d1b3a6c40456735": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d37e2d8dcd8a40d681f4536012442a10": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe068259cd254dca8f3ca86f8a0e597a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
