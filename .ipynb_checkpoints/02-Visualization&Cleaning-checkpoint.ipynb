{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "from data.util.paths import DATA_PATH\n",
    "from lib.util.paths import PIPELINE_PATH\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lib.transformers import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.processing import *\n",
    "from data.scripts.project_data import DataLoader\n",
    "from data.util.environment_variables import COUNTRY_CODES, M49_TO_ISO3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_pipe, extracted_pipe = load_from_pkl('api_pipe',path=os.path.join(PIPELINE_PATH,'api')), load_from_pkl('extracted_pipe',path=os.path.join(PIPELINE_PATH,'extracted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ba74d3ccc149419db7dadf01fd06fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=297546.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a515b9c2cd40008c95a98f19896c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(db_name='jazz_album',db_path=DATA_PATH,db_dialect='sqlite')\n",
    "extracted_df, api_df = data_loader.load_extracted_data(), data_loader.load_api_data()\n",
    "extracted_df = extracted_pipe.fit_transform(extracted_df)\n",
    "api_df = api_pipe.fit_transform(api_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(extracted_df,api_df,on='release_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del extracted_df, api_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Column Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_set = {\n",
    "    'format': {\n",
    "        'description': 'format_description_', \n",
    "        'name': 'format_name_', \n",
    "        'text': ('format_text_clean'),\n",
    "        'quantity': ('format_quantity')\n",
    "    },\n",
    "    'geography': {\n",
    "        'superregion': 'superregion_',\n",
    "        'region': 'region_',\n",
    "        'country': 'country_'\n",
    "    },\n",
    "    'timeperiod': {\n",
    "        'period': 'period_',\n",
    "        'era': 'era_'\n",
    "    },\n",
    "    'genre': 'genre_',\n",
    "    'style': 'style_',\n",
    "    'null': None,\n",
    "    'indicator': lambda x: x.max() == 1 and x.min() == 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_store = ColumnStore()\n",
    "column_store.fit(df,col_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Number of Records over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_year_range, era_year_range = make_year_range_dict(column_store._timeperiod_period,df=df), make_year_range_dict(column_store._timeperiod_era,df=df)\n",
    "time_period_year_range = dict(**period_year_range,**era_year_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_count_series = df.groupby(by='year')['market_value'].count()\n",
    "year_count_series[1936] = 0\n",
    "year_count_series.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_colors = {\n",
    "    'period_big_band': 'red',\n",
    "    'period_bebop': 'pink',\n",
    "    'period_cool': 'blue',\n",
    "    'period_fusion': 'orange',\n",
    "}\n",
    "era_colors = {\n",
    "    'era_swing': 'purple',\n",
    "    'era_modern': 'green',\n",
    "    'era_contemporary': 'gold'\n",
    "}\n",
    "time_period_colors = dict(**period_colors,**era_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variable_with_time_periods(year_series,time_periods,time_period_colors,**kwargs):\n",
    "    plt.figure(figsize=(20,10))\n",
    "\n",
    "    #Setting up plotting helpers\n",
    "    dev_constant = 200\n",
    "    convert_to_label = lambda x: ' '.join(x.split('_')).title()\n",
    "\n",
    "    #Plotting\n",
    "    plt.plot(year_series)\n",
    "    for time_period, year_range in time_periods.items():\n",
    "        if 'period' in time_period:\n",
    "            try:\n",
    "                min_, max_, hatch_ = 0, year_series.loc[year_range], '/'\n",
    "            except KeyError:\n",
    "                print(year_range)\n",
    "        else:\n",
    "            min_, max_, hatch_ = year_series.loc[year_range], year_series.loc[year_range]+dev_constant, None\n",
    "\n",
    "        plt.fill_between(year_range,max_,min_,alpha=0.25,color=time_period_colors[time_period],hatch=hatch_,label=convert_to_label(time_period))\n",
    "    \n",
    "    for attr in (kwargs):\n",
    "        try:\n",
    "            getattr(plt,attr)(kwargs[attr])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variable_with_time_periods(year_count_series,time_period_year_range,time_period_colors,xlabel='Year',ylabel='Albums',title='Albums released per Year according to Dominant Jazz Time Period')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above, there was a massive explosion in the number of Jazz albums released per year in the 1950s, with a cyclical rise through the rest of the 20th century and into the 21st. In the Contemporary Jazz Era/Jazz Fusion Period, we see that the number of Jazz Albums released it at its highest, most likely due to the massive influence of Jazz on other genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_jazz_album_count = df[df[column_store._genre].sum(axis=1)==0].groupby(by='year').count()['market_value']\n",
    "pure_jazz_album_count[1934], pure_jazz_album_count[1936] = 0,0\n",
    "pure_jazz_album_count.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variable_with_time_periods(pure_jazz_album_count,time_period_year_range,time_period_colors,xlabel='Year',ylabel='Albums',title='Albums released per Year according to Dominant Jazz Time Period')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the figure above is effectively identical to the one which includes non 'Pure Jazz' albums, indicating that the rising trend in album releases is not primarily due to the incorporation of Jazz into other styles, but instead a growth of the music in its purest form over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Value\n",
    "### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['market_value'])\n",
    "plt.ylabel('Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we see that there is a huge left skew for market_value, which means we need to remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_remover = OutlierRemover('market_value')\n",
    "outlier_remover.fit_transform(df)\n",
    "print('OutlierRemover remover %s rows' % (len(df)-len(outlier_remover.fit_transform(df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(outlier_remover.transform(df)['market_value']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing entries with ``market_value`` values exceeding 3 standard deviations from the mean, we see that the distribution has skewed less, making it a prime candidate for log treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log(outlier_remover.transform(df)['market_value']));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution of Market Value over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('2020 Market Value in USD')\n",
    "plt.plot(df.groupby(by='year')['market_value'].mean())\n",
    "mean_value = df.groupby(by='year')['market_value'].mean()\n",
    "std_error = df.groupby(by='year')['market_value'].std()\n",
    "plt.fill_between(std_error.index, mean_value-std_error, mean_value+std_error, alpha=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we see that even after removing the most offending outliers, there is still tremendous variation in the price of Jazz records, whic is particularly large in the mid 20th century, and slowly reduces over time, but never to a very small margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot_columns = list(filter(lambda x: df[x].dtype in (float,int) and x not in ['master_id','release_id'],column_store._rest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_subplots(df, var, var_list,nrows,ncols,figsize=(60,60)):\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=nrows,ncols=ncols,figsize=figsize)\n",
    "\n",
    "\n",
    "    for row_idx, row in enumerate(ax):\n",
    "        for col_idx, col in enumerate(row):\n",
    "            row_modifier = len(var_list)-ncols*row_idx\n",
    "            list_idx = len(var_list)-row_modifier+col_idx\n",
    "            col_column = var_list[list_idx]\n",
    "            col.set_title(col_column,fontdict={'fontsize':50})\n",
    "            col.scatter(df[col_column],df[var],edgecolor='white')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr_subplots(df,'market_value',pairplot_columns,4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plots above, there are not many clear relationships that can be identified between the ``market_value`` feature and the numerical features of the dataset. This implies that performance of the model will rely heavily on an efficient encoding of non-numerical data, such as genre, style, artist etc. in order to be able to predict the market value of a given record with any certainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_series(df,correlation_column,columns=None):\n",
    "    df = df.copy()\n",
    "    \n",
    "    if not columns:\n",
    "        columns = df.columns\n",
    "    \n",
    "    return pd.Series({\n",
    "        column: np.corrcoef(\n",
    "            df[correlation_column].values,\n",
    "            df[column].values\n",
    "        )[0][1]\n",
    "        for column in columns\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_value_indicator_correlations = get_correlation_series(df,'market_value',column_store._indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_value_indicator_correlations.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, it is clear that the indicator variables are not very highly correlated with ``market_value`` either. As such, we hope that via the leveraging of the multitude of categorical variables, we can improve the result of our price predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign = market_value_indicator_correlations.apply(lambda x: 'positive' if x >= 0 else 'negative')\n",
    "market_value_indicator_correlations = pd.DataFrame(\n",
    "    {'correlation': market_value_indicator_correlations.abs().values,'Sign': sign.values},\n",
    "    index = market_value_indicator_correlations.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_value_indicator_correlations.sort_values(by='correlation',ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see by investigating the top correlations, albums from Japan in particular seem to be the most highly correlated with market value, followed by the formats of Vinyl and CD. Interestingly, there seems to be a positive correlation on price for Vinyl albums, and a negative correlation for CDs, which is what one would generally expect. We also observe that limited edition and reissued albums tend to be priced higher, which also makes sense. An interesting takeaway is that albums from europe and north america tend to be negatively correlated with price, which may be linked to their dominance in the genre and the sheer volume of albums they release. Furthermore, we see that the Hard Bop and Modal jazz styles tend to be the most positively correlated with ``market_value``, which is also understandable, given that these were the dominant styles during the modern jazz era, which defines the genre as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_sum = df[column_store._genre].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.xlabel('Additional Genre')\n",
    "plt.ylabel('# of Albums')\n",
    "plt.xticks(rotation=30)\n",
    "plt.bar(genre_sum.index,genre_sum);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many 'pure' jazz albums\n",
    "pure_jazz_albums = len(df[df[column_store._genre].sum(axis=1)==0])\n",
    "print('There are {} albums which exclusively list Jazz as a genre, {}% of the dataset'.format(pure_jazz_albums,round(100*pure_jazz_albums/len(df),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_sum = df[column_store._style].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_sum.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_sum_top_10 = style_sum[style_sum > style_sum.quantile(0.9)].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "plt.xlabel('Listed Styles')\n",
    "plt.ylabel('# of Albums')\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(style_sum_top_10.index,style_sum_top_10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As some of the estimators we will use as part of our estimation are sensitive to excessive dimensionality, we will implement a transformer which retains only those indicator variables which are positive for over a certain threshold of entries. This is introduced below as the IndicatorConsolidator transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_consolidator = IndicatorConsolidator(columns=column_store._style,output_column='style_Other',threshold=250,counter_name='counter_style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[column_store._style].sum().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_consolidator.fit_transform(df)[['style_Other','counter_style']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_description_sum = df[column_store._format_description].sum().sort_values(ascending=False)\n",
    "format_description_sum.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_description_sum.iloc[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_consolidator = IndicatorConsolidator(columns=column_store._format_description,output_column='format_description_Other',threshold=None,counter_name='counter_format_description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_consolidator.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_name_sum = pd.get_dummies(df['format_name']).sum().sort_values(ascending=False)\n",
    "format_name_sum.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "plt.xlabel('Format Names')\n",
    "plt.ylabel('# of Albums')\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(format_name_sum.index,format_name_sum)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that it would be wise to reduce the ``format_name`` indicator variable dimensionality, as there are really three non-trivially large format categories, namely ``CD``, ``Vinyl`` and ``Cassette``. The rest we will combine into an ``Other`` indicator. We will also combine ``CD`` and ``CDr``, as these formats are essentially equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_name_consolidator = IndicatorConsolidator(output_column='format_name_other',threshold=5000)\n",
    "format_name_consolidator.fit_transform(pd.get_dummies(df['format_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Most Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df = gpd.read_file(os.path.join(DATA_PATH,'countries/ne_110m_admin_0_countries.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_countries = list(filter(lambda x: x not in ['country_yugoslavia','country_ussr','country_taiwan'],column_store._geography_country))\n",
    "country_album_count = df[visualization_countries].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = pd.Series([COUNTRY_CODES[country.split('_')[-1]] for country in visualization_countries],index=visualization_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = pd.DataFrame(country_album_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df['codes'] = country_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df['ISO_A3'] = country_df.loc[:,'codes'].map(M49_TO_ISO3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df.sort_values(0,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = map_df.set_index('ISO_A3').join(country_df.set_index('ISO_A3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = min(merge[0]),max(merge[0])\n",
    "fig, ax = plt.subplots(1,figsize=(20,20))\n",
    "merge.plot(column=0,cmap='gnuplot',linewidth=0.8,ax=ax,edgecolor='0.8')\n",
    "ax.axis('off')\n",
    "sm = plt.cm.ScalarMappable(cmap='gnuplot',norm=plt.Normalize(vmin=vmin,vmax=vmax))\n",
    "sm._a = []\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar = fig.colorbar(sm,cax=cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Level Features\n",
    "## Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(db_name='jazz_album',db_path=DATA_PATH,db_dialect='sqlite')\n",
    "image_embeddings = data_loader.load_high_level_features()\n",
    "image_embedding_df = pd.DataFrame()\n",
    "for feature_chunk in tqdm(high_level_features):\n",
    "    image_embedding_df = pd.concat([image_embedding_df,feature_chunk],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embedding_df = image_embedding_df.reset_index(drop=True).drop('index',axis=1).astype({'release_id':np.uint32,'bitmap':np.uint8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(image_embedding_df,on='release_id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del image_embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_set['image_embedding'] = 'feature_'\n",
    "column_store = ColumnStore()\n",
    "column_store.fit(df,col_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2d = ColumnTransformer([\n",
    "    ('scale',StandardScaler(),list(column_store._image_embedding)),\n",
    "    ('pca_2d',PCA(n_components=2,random_state=0),list(column_store._image_embedding))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_2d = ColumnTransformer([\n",
    "    ('scale', StandardScaler(), list(column_store._image_embedding)),\n",
    "    ('umap', umap.UMAP(n_components=2,random_state=0,verbose=True), list(column_store._image_embedding))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_output = umap_2d.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pca_2d.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pca_2d = PCA(n_components=2,random_state=0)\n",
    "pca_3d = PCA(n_components=3,random_state=0)\n",
    "scale_pca_2d = Pipeline([('scaler',scaler),('pca',pca_2d)])\n",
    "scale_pca_3d = Pipeline([('scaler',scaler),('pca',pca_3d)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_2d = scale_pca_2d.fit_transform(data)\n",
    "embedding_3d = scale_pca_3d.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_nd_columns = lambda n: ['embedding_%sd_%s' % (n,i) for i in range(n)]\n",
    "embedding_2d_columns, embedding_3d_columns = embedding_nd_columns(2), embedding_nd_columns(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(\n",
    "    [combined_df,\n",
    "     pd.DataFrame(embedding_2d,columns=embedding_2d_columns),\n",
    "     pd.DataFrame(embedding_3d,columns=embedding_3d_columns)\n",
    "    ],\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmap(n, name='hsv'):\n",
    "    return plt.cm.get_cmap(name, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_indicator_3d(df, columns, embedding_columns=None,**kwargs):\n",
    "    df = df.copy()\n",
    "    if not embedding_columns:\n",
    "        embedding_columns = list(filter(lambda x: 'embedding_3d' in x,df.columns))\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    if kwargs.get('colors'):\n",
    "        colors = kwargs.get('colors')\n",
    "    else:\n",
    "        cmap = get_cmap(len(columns))\n",
    "        colors = [cmap(index) for index in range(len(columns))]\n",
    "                  \n",
    "    for index,column in enumerate(columns):\n",
    "        column_embedding = df[df[column]==1][embedding_columns]\n",
    "        ax.scatter(\n",
    "            column_embedding.iloc[:,0],\n",
    "            column_embedding.iloc[:,1],\n",
    "            column_embedding.iloc[:,2],\n",
    "            label=column.split('_')[-1],\n",
    "            color=colors[index],\n",
    "            alpha=0.75\n",
    "        )\n",
    "    \n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_indicator_2d(df, columns,embedding_columns=None,**kwargs):\n",
    "    df = df.copy()\n",
    "    if not embedding_columns:\n",
    "        embedding_columns = list(filter(lambda x: 'embedding_2d' in x,df.columns))\n",
    "    cmap = get_cmap(len(columns))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    if kwargs.get('colors'):\n",
    "        colors = kwargs.get('colors')\n",
    "    else:\n",
    "        cmap = get_cmap(len(columns))\n",
    "        colors = [cmap(index) for index in range(len(columns))]  \n",
    "    \n",
    "    for index,column in enumerate(columns):\n",
    "        column_embedding = df[df[column]==1][embedding_columns]\n",
    "        plt.scatter(\n",
    "            column_embedding.iloc[:,0],\n",
    "            column_embedding.iloc[:,1],\n",
    "            label=column.split('_')[-1],\n",
    "            color=colors[index],\n",
    "            alpha=0.25,\n",
    "            edgecolor='white'\n",
    "        )\n",
    "    \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_indicator_2d(combined_df,region_columns,embedding_2d_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['market_value'].quantile([0.25,0.5,0.75,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_quantile(x,lower,upper):\n",
    "    if x >= lower and x <= upper:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for quantile in [0.25,0.5,0.75,1]:\n",
    "    combined_df['market_value_quantile_%s' % quantile] = combined_df['market_value'].apply(identify_quantile,lower=combined_df['market_value'].quantile(quantile-0.25),upper=combined_df['market_value'].quantile(quantile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_value_quantiles = list(filter(lambda x: 'market_value_quantile' in x,combined_df.columns))\n",
    "combined_df[market_value_quantiles].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = [int(random.random()*len(combined_df)) for i in range(5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = combined_df.loc[random_sample,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_indicator_3d(test,market_value_quantiles,embedding_3d_columns,colors=['blue','orange','red','green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_value_embedding_3d_correlations = pd.Series({column:np.corrcoef(combined_df['market_value'].values,combined_df[column].values)[0][1] for column in ['embedding_3d_%s' % i for i in range(3)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_value_embedding_3d_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_10d = PCA(n_components=10,random_state=0)\n",
    "scale_pca_10d = Pipeline([('scaler',scaler),('pca',pca_10d)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_10d = pca_10d.fit_transform(data)\n",
    "embedding_10d_columns = embedding_nd_columns(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([\n",
    "    combined_df,\n",
    "    pd.DataFrame(embedding_10d,columns=embedding_10d_columns)\n",
    "    ],axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_corr_series(combined_df,'market_value',embedding_10d_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(embedding_2d_columns+embedding_3d_columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pkl(combined_df,'combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_tr,y_tr],axis=1)\n",
    "test_df = pd.concat([X_te,y_te],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pkl(train_df,'train')\n",
    "save_to_pkl(test_df,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
